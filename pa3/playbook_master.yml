---
# EECS 4287/5287: Principles of Cloud Computing
# Author: Adam Catalfano, AJ
# Created: Fall 2021
#
# This playbook provisions the remote Instances
# and starts running the Kafka/CouchDB architecture
# with 2 Kafka brokers and 1 Zookeeper instance

# NOTE: wherever 'kafka1' and 'kafka2' are mentioned,
#     kafka1 = VM2 = kafka/zookeeper/consumer instance
#     kafka2 = VM3 = kafka/couchDB instance

# TODO: with FQCN I'm pretty sure the "collections:" field is unneeded

#####################################################################
### Play 1: Terminate Any Existing Cloud Instances
#
# Run the cleanup master playbook to cleanup
# any remote instances if they exist
#####################################################################
- name: 'Play 1: Terminate Any Existing Cloud Instances'
  ansible.builtin.import_playbook: playbook_master_cleanup.yml

#####################################################################
### Play 2: Install/Configure Base Dependencies
#
# Install pip, configure python to point to python3,
# Install python packages boto3, botocore, and docker
#####################################################################
- name: 'Play 2: Install and Configure Base Dependencies'
  hosts: MyLocalVMs
  remote_user: ubuntu
  # strategy: debug

  tasks:
  - name: Aptitude Upgrade
    ansible.builtin.include_tasks: tasks/playbook_aptitude_upgrade.yml
  - name: Configure Python Versions
    ansible.builtin.include_tasks: tasks/playbook_configure_python.yml
  - name: Configure File Modes for SSH, etc.
    ansible.builtin.include_tasks: tasks/playbook_configure_file_modes.yml

  - name: Install boto3, botocore, and docker python packages
    ansible.builtin.pip:
      name:
        - boto
        - boto3
        - botocore
        - docker

#####################################################################
### Play 3: Create EC2 Security Groups
#
# Create Security Groups on AWS
#####################################################################
- name: 'Play 3: Create EC2 Security Groups'
  hosts: MyLocalVMs
  remote_user: ubuntu
  strategy: debug
  vars_files:
  - variables/aws_vars.yml
  collections:
  - amazon.aws

  tasks:
  - name: Build AWS EC2 Security Groups
    ansible.builtin.include_tasks: tasks/aws_instance_management/playbook_create_security_groups.yml

#####################################################################
### Play 4: Create AWS EC2 Cloud Instances
#
# Provision instances on the cloud
#####################################################################
- name: 'Play 4: Create AWS EC2 Instances'
  hosts: MyLocalVMs
  remote_user: ubuntu
  vars:
    zookeeper_ip: vm2_ip
    couchdb_ip: vm3_ip
    zookeeper_private_ip: vm2_private_ip
    couchdb_private_ip: vm3_private_ip
  # strategy: debug
  collections:
  - amazon.aws

  tasks:
  - name: provision AWS instances
    ansible.builtin.include_tasks: tasks/aws_instance_management/playbook_create_aws_vms.yml

#####################################################################
### Play 4: Install Common Dependencies on all Cloud Instances
#
# Aptitude Upgrade and Install Kafka on cloud instances
#####################################################################
# - name: 'Play 4: Install Common Dependencies on all Cloud Instances'
#   hosts: "{{ all_remote }}"
#   remote_user: ubuntu
#   vars_files:
#   - variables/path_names.yml
#   - variables/group_names.yml
#   collections:
#   - amazon.aws
#   # strategy: debug
#   tasks:
#   - ansible.builtin.include_tasks: tasks/playbook_aptitude_upgrade.yml
#   - ansible.builtin.include_tasks: tasks/vms/common/playbook_install_kafka.yml
#   - ansible.builtin.include_tasks: tasks/vms/common/playbook_common_kafka_configs.yml
#   - name: Install daemon for running programs later (without termination)
#     become: yes
#     ansible.builtin.apt: name=daemon

#####################################################################
### Play 5: Install Dependencies on the VM3 Cloud Instance
#
# Install Zookeeper and Kafka on the Zookeeper/Kafka/Consumer host
# Add and configure the consumer file
#####################################################################
# - name: 'Play 5: Install Dependencies on Zookeeper/Kafka/Consumer Cloud Instance'
#   hosts: "{{ kafka1_zookeeper_consumer }}"
#   remote_user: ubuntu
#   vars_files:
#   - variables/group_names.yml
#   # strategy: debug
#   tasks:
#   - ansible.builtin.include_tasks: tasks/vms/vm2/playbook_configure_zookeeper.yml
#   - ansible.builtin.include_tasks: tasks/vms/vm2/playbook_install_python_dependencies.yml

#   - name: copy consumer.py over to remote instance
#     ansible.builtin.copy:
#       src: file_srcs/consumer.py
#       dest: ~/consumer.py

#   - name: set couchDB username variable in consumer.py
#     ansible.builtin.replace:
#       path: ~/consumer.py
#       regexp: (?<=username = ')[^']*(?=')
#       replace: admin

#   - name: set couchDB password variable in consumer.py
#     ansible.builtin.replace:
#       path: ~/consumer.py
#       regexp: (?<=password = ')[^']*(?=')
#       replace: admin%20password
#####################################################################
### Play 5: Install Docker + K8S and copy over K8S Files
#
# Install K8S, Docker, and Dependencies on all remotes
#####################################################################
- name: 'Play 5: Install Docker + K8S and copy over K8S Files'
  hosts: "{{ all_remote }}"
  remote_user: ubuntu
  vars_files:
  - variables/group_names.yml
  strategy: debug
  tasks:
  - name: Install Docker and K8S
    ansible.builtin.include_tasks: tasks/execute/k8s/playbook_install_docker_and_k8s.yml

#####################################################################
### Play 6: Reboot the remote instances
#
#  Reboot remotes
#####################################################################
# TODO: may not need this at all...
# - name: 'Play 6: Reboot the remote instances'
#   hosts: MyLocalVMs
#   remote_user: ubuntu
#   collections:
#   - amazon.aws
#   tasks:
#   - name: Reboot AWS Instances
#     amazon.aws.ec2_instance:
#       instance_ids:
#       - "{{ master_instance.instance_id }}"
#       - "{{ regular_instance.instance_id }}"
#       state: rebooted

#   - name: Pause for Reboot to finish
#     ansible.builtin.pause:
#       seconds: 30

#   - name: Wait for SSH to come up
#     debugger: on_failed
#     delegate_to: "{{ item.public_dns_name }}"
#     ansible.builtin.wait_for:
#       timeout: 60
#       port: 22
#       state: started
#     loop: [ "{{ master_instance }}", "{{ regular_instance }}" ]

#####################################################################
### Play 7: Configure and Launch K8S Master
#
#  Configure and Start
#####################################################################
- name: 'Play 7: Configure and Launch K8S Master'
  hosts: "{{ k8s_master }}"
  remote_user: ubuntu
  vars_files:
  - variables/group_names.yml
  - variables/path_names.yml
  - variables/credentials/docker.yml
  - variables/docker_vars.yml
  strategy: debug
  collections:
  - community.docker
  tasks:
  # TODO: drop these 2 tasks
  # - name: debug whats in hostvars
  #   debug:
  #     var: hostvars

  # - name: wait to grab the output
  #   ansible.builtin.pause:
  #     seconds: 35


  # - name: Add master as insecure registry
  #   # vars:
  #   #   k8s_master_ip: "{{ groups[k8s_master][0] }}"
  #   ansible.builtin.include_tasks: tasks/execute/k8s/playbook_add_insecure_registries_config.yml

  - name: Set Hostname Aliases on K8S Master
    become: yes
    vars:
      lines:
      - "{{ inventory_hostname }} kubemaster kubeworker1"
      - "{{ hostvars['127.0.0.1'].vm2_private_ip }} kubemaster kubeworker1"
      # TODO: these 2 lines really needed???
      - 127.0.0.1 localhost
      - 127.0.1.1 acat-vm3.novalocal acat-vm3
    ansible.builtin.lineinfile:
      path: /etc/hosts
      line: "{{ lines | join('\n') }}"

  - name: Copy over kubernetes files
    ansible.builtin.copy:
      src: file_srcs/containers/
      dest: "{{ containers_directory }}"

  - name: Configure image server IP address
    ansible.builtin.replace:
      path: "{{ containers_directory }}/Service_Job/matinv-server-job.yaml"
      regexp: '(?<=image: )(?:\d+\.)+\d+(?=:5000)'
      replace: "{{ inventory_hostname }}"

  - name: Install Pip for Python3
    become: yes
    ansible.builtin.apt:
      name:
      - python3-pip

  - name: Install docker and docker-compose python package
    become: yes
    ansible.builtin.pip:
      name:
      - docker
      - docker-compose

  # - name: Change permissions for docker.sock file
  #   become: yes
  #   ansible.builtin.file:
  #     path: /var/run/docker.sock
  #     mode: 0666

  - name: Install docker compose
    ansible.builtin.include_tasks: tasks/execute/k8s/playbook_install_docker_compose.yml

  - name: Make registry directory
    ansible.builtin.file:
      state: directory
      path: ~/registry

  - name: Copy over docker-compose file
    ansible.builtin.copy:
      dest: ~/registry/docker-compose.yml
      src: ./file_srcs/registry/docker-compose.yml

  - name: Compose the registry
    community.docker.docker_compose:
      project_src: ~/registry/
  # TODO: replacing this one vvvv
  # - name: Launch the docker private registry
  #   become: yes
  #   community.docker.docker_container:
  #     name: registry
  #     image: registry:2
  #     published_ports:
  #     - 5000:5000
  #     detach: yes
  #     restart_policy: always

  # - name: Start private registry
  #   ansible.builtin.shell: daemon -D ~/ -- docker-compose up
  # - name: Install pip
  #   become: yes
  #   ansible.builtin.apt:
  #     name:
  #     - python3-pip

  # - name: Install docker python package
  #   become: yes
  #   ansible.builtin.pip:
  #     name:
  #     - docker

  - name: Start and Prepare K8S Master
    ansible.builtin.include_tasks: tasks/execute/k8s/playbook_start_and_prepare_k8s_master.yml

  - name: Store join command to register
    ansible.builtin.shell: kubeadm token create --print-join-command
    register: joinCommandOutput

  - name: Store join command as a fact
    ansible.builtin.set_fact:
      joinCommand: "{{ joinCommandOutput.stdout }}"

#####################################################################
### Play 8: Configure K8S worker and join cluster
#
# Configure worker and join K8S Cluster
#####################################################################
- name: 'Play 8: Configure K8S worker and join cluster'
  hosts: "{{ k8s_worker }}"
  remote_user: ubuntu
  vars_files:
  - variables/group_names.yml
  strategy: debug
  tasks:
  - name: Set Hostname Aliases on K8S Worker
    become: yes
    vars:
      lines:
      - "{{ inventory_hostname }} kubeworker2"
      - "{{ hostvars['127.0.0.1'].vm3_private_ip }} kubeworker2"
      # TODO: these 2 lines really needed???
      - 127.0.0.1 localhost
      - 127.0.1.1 acat-vm3.novalocal acat-vm3
    ansible.builtin.lineinfile:
      path: /etc/hosts
      line: "{{ lines | join('\n') }}"

  - name: Join K8S Cluster
    vars:
      k8s_master_ip: "{{ groups[k8s_master][0] }}"
    become: yes
    ansible.builtin.shell: "{{ hostvars[k8s_master_ip].joinCommand }} --node-name kubeworker2"

#####################################################################
### Play 9: Untaint master, create secret, build docker image, and run pods
#
# Untaint K8S master to be a worker and build docker image
#####################################################################
- name: 'Play 9: Untaint master, create secret, build docker image, and run pods'
  hosts: "{{ k8s_master }}"
  remote_user: ubuntu
  vars_files:
  - variables/group_names.yml
  - variables/path_names.yml
  - variables/docker_vars.yml
  - variables/credentials/docker.yml
  collections:
  - community.docker
  tasks:
  - name: Untaint K8S master
    ansible.builtin.include_tasks: tasks/execute/k8s/playbook_untaint_master.yml

  - name: Create secret
    ansible.builtin.include_tasks: tasks/execute/k8s/playbook_create_secret.yml

  # TODO: shouldn't be needed vvvvv (also delete the playbook_install_docker_collection_dependencies.yml if not using!)
  # - name: Configure Python
  #   ansible.builtin.include_tasks: tasks/playbook_configure_python.yml

  # - name: Install dependencies required to run community.docker tasks
  #   ansible.builtin.include_tasks: tasks/execute/k8s/playbook_install_docker_collection_dependencies.yml

  # - ansible.builtin.include_tasks: tasks/playbook_configure_python.yml

  # - ansible.builtin.include_tasks: tasks/playbook_aptitude_upgrade.yml


  # - name: Install DistUtils for Python3
  #   become: yes
  #   ansible.builtin.apt:
  #     name: python3-distutils

  - name: Build docker image
    ansible.builtin.include_tasks: tasks/execute/k8s/playbook_build_docker_image.yml

#####################################################################
### Play 7: Reboot Remotes
#
# Reboot the AWS instances
#####################################################################
# - name: "Play 7: Reboot Remotes"
#   hosts: MyLocalVMs
#   remote_user: ubuntu
#   strategy: debug
#   collections:
#   - amazon.aws
#   tasks:
#   - name: Reboot EC2 Instances
#     amazon.aws.ec2_instance:
#       state: restarted
#       instance_ids:
#       - "{{ master_instance.instance_id }}"
#       - "{{ regular_instance.instance_id }}"

# TODO: TODO: TODO: TODO: ^^^^^^^ MAY BE UNNECESSARY
# BUUUUT MORE IMPORTANTLY:
# next will need to run kubectl get nodes -o json | jq '.items[].spec.taints' on master
# then run: kubectl taint nodes kubemaster <<<KEV>>>:<<<EFFECT>>> (based on key and effect values from previous command)
#
# TODO: TODO: TODO: TODO: THE kubectl COMMAND IS NOT WORKING! LOOK AT aws_vars.yml (OR NOT, MINIMAL HELP, BUT SOME CLEANUP PROB NEEDED!)
#                 BUT ALSO LOOK AT THE DIFFERENCES OF REQ'D PORTS FOR K8S IN THE SLACK POST (FIRST ONE ON OCT 27)
#                 AND TRY TO FIGURE IT OUT!!!!!!!!!!


#####################################################################
### Play 7: Install Dependencies on the VM3 Cloud Instance
#
# Install and configure CouchDB and Kafka on the CouchDB/Kafka host
#####################################################################
# - name: 'Play 7: Install Dependencies on CouchDB/Kafka Cloud Instance'
#   hosts: "{{ kafka2_couchDB }}"
#   remote_user: ubuntu
#   vars_files:
#   - variables/group_names.yml
#   # strategy: debug
#   tasks:
#   - ansible.builtin.include_tasks: tasks/vms/vm3/playbook_install_couchdb.yml

#   - ansible.builtin.include_tasks: tasks/vms/vm3/playbook_configure_couchdb.yml
#     vars:
#       password: admin password


#####################################################################
### Play 8: Start Zookeeper on the VM2 Cloud Instance
#
# Start Zookeeper on the Zookeeper/Kafka/Consumer host
#####################################################################
# - name: 'Play 8: Install Dependencies on CouchDB/Kafka Cloud Instance'
#   hosts: "{{ kafka1_zookeeper_consumer }}"
#   remote_user: ubuntu
#   vars_files:
#   - variables/group_names.yml
#   - variables/path_names.yml
#   # strategy: debug
#   tasks:
#   - name: Start Zookeeper
#     ansible.builtin.shell: "daemon -- {{ kafka_directory }}/bin/zookeeper-server-start.sh {{ kafka_directory }}/config/zookeeper.properties"



#####################################################################
### Play 9: Run CouchDB on vm3
#
# Start up CouchDB on the Zookeeper/Kafka host
#####################################################################
# - name: 'Play 9: Run CouchDB on vm3'
#   hosts: "{{ kafka2_couchDB }}"
#   remote_user: ubuntu
#   vars_files:
#   - variables/group_names.yml
#   tasks:
#   - name: Start The CouchDB Service
#     become: yes
#     service:
#       name: couchdb
#       state: restarted


#####################################################################
### Play 10: Run Kafka on all remotes
#
# Start up Kafka on all remote hosts
#####################################################################
# - name: 'Play 10: Run Kafka on all remote hosts'
#   hosts: "{{ all_remote }}"
#   remote_user: ubuntu
#   vars_files:
#   - variables/group_names.yml
#   - variables/path_names.yml
#   vars:
#     provisioner_ip: "{{ groups['MyLocalVMs'].0 }}"
#   tasks:
#   - ansible.builtin.include_tasks: tasks/execute/playbook_start_kafka.yml
#     vars:
#       zookeeper_ip: "{{ hostvars[provisioner_ip]['vm2_ip'] }}"


#####################################################################
### Play 11: Run Kafka and Consumer on vm2
#
# Start up Consumer on the Zookeeper/Kafka/Consumer host
#####################################################################
# - name: 'Play 11: Run Consumer on vm2'
#   hosts: "{{ kafka1_zookeeper_consumer }}"
#   remote_user: ubuntu
#   vars_files:
#   - variables/path_names.yml
#   - variables/group_names.yml
#   vars:
#     provisioner_ip: "{{ groups['MyLocalVMs'].0 | default('127.0.0.1') }}"

#   tasks:
#   - ansible.builtin.include_tasks: tasks/execute/playbook_start_consumer.yml
#     vars:
#       zookeeper_ip: "{{ hostvars[provisioner_ip]['vm2_ip'] }}"
#       couchDB_ip: "{{ hostvars[provisioner_ip]['vm3_ip'] }}"


#####################################################################
### Play 12: Provision Producers and run script
#
# Provision VM1.1 and VM1.2 and execute producer.py on each
#####################################################################
# - name: 'Play 12: Provision Producers and run script'
#   ansible.builtin.import_playbook: playbook_master_run_producers.yml
...
