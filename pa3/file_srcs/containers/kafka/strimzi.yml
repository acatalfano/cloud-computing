---
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: kafka-cluster
spec:
  kafka:
    # TODO: documentation calls this # of replica NODES not PODS.....will this still work????
    replicas: 5
    logging:
      type: inline
      loggers:
        kafka.root.logger.level: "INFO"
    resources:
      # minimum memory and cpu requested for cluster
      requests:
        memory: 64Gi
        cpu: "8"
      # max memory and cpu kafka cluster is allowed to use
      limits:
        memory: 64Gi
        cpu: "12"
    readinessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 15
      timeoutSeconds: 5
    jvmOptions:
      -Xms: 128M
      -Xmx: 256M
    # Ansible should replace the 1.2.3.4 (if using the custom image)
    # image: 1.2.3.4:5000/teamx-kafka-base:latest
    listeners:
    - name: plain
      port: 9092
      type: internal
      tls: false
      configuration:
        useServiceDnsDomain: yes
    - name: tls
      port: 9093
      type: internal
      tls: yes
      authentication:
        type: tls
    - name: external
      port: 9094
      type: route
      tls: yes
    # authorization:
    #   type: simple
    config:
      auto.create.topics.enable: "false"
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      default.replication.factor: 3
      min.insync.replicas: 2
      inter.broker.protocol.version: 3.0
      ssl.cipher.suites: "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"
      ssl.enabled.protocols: "TLSv1.2"
      ssl.protocol: "TLSv1.2"
    storage:
      type: persistent-claim
      size: 1000Gi
    # rack:
    #   topologyKey: topology.kubernetes.io/zone
    # metricsConfig:
    #   type: jmxPrometheusExporter
    #   valueFrom:
    #     configMapKeyRef:
    #       name: my-config-map
    #       key: my-key
    # ...
  zookeeper:
    replicas: 1
    logging:
      type: inline
      loggers:
        zookeeper.root.logger: "INFO"
    resources:
      # TODO: may need to lower this...
      requests:
        memory: 8Gi
        cpu: "2"
      limits:
        memory: 8Gi
        cpu: "2"
    jvmOptions:
      -Xms: 128M
      -Xmx: 256M
    storage:
      type: persistent-claim
      size: 1000Gi
    # metricsConfig:
    #   # ...
  # entityOperator:
  #   tlsSidecar:
  #     resources:
  #       requests:
  #         cpu: 200m
  #         memory: 64Mi
  #       limits:
  #         cpu: 500m
  #         memory: 128Mi
  #   topicOperator:
  #     watchedNamespace: my-topic-namespace
  #     reconciliationIntervalSeconds: 60
  #     logging:
  #       type: inline
  #       loggers:
  #         rootLogger.level: "INFO"
  #     resources:
  #       requests:
  #         memory: 512Mi
  #         cpu: "1"
  #       limits:
  #         memory: 512Mi
  #         cpu: "1"
  #   userOperator:
  #     watchedNamespace: my-topic-namespace
  #     reconciliationIntervalSeconds: 60
  #     logging:
  #       type: inline
  #       loggers:
  #         rootLogger.level: INFO
  #     resources:
  #       requests:
  #         memory: 512Mi
  #         cpu: "1"
  #       limits:
  #         memory: 512Mi
  #         cpu: "1"
  # kafkaExporter:
  #   # ...
  # cruiseControl:
  #   # ...
  #   tlsSidecar:
  #     # ...
...

# apiVersion: v1
# kind: Service
# metadata:
#   name: kafka
#   labels:
#     app: kafka
# spec:
#   ports:
#   - port: 9092
#     name: kafka-port
#   clusterIP: None
#   selector:
#     app: kafka
# ---
# apiVersion: apps/v1
# kind: StatefulSet
# metadata:
#   name: kafka-set
# spec:
#   selector:
#     matchLabels:
#       app: kafka # has to match .spec.template.metadata.labels
#   serviceName: "kafka"
#   replicas: 1 # by default is 1
#   minReadySeconds: 10 # by default is 0
#   template:
#     metadata:
#       labels:
#         app: kafka # has to match .spec.selector.matchLabels
#     spec:
#       terminationGracePeriodSeconds: 10
#       containers:
#       - name: kafka
#         image: 54.197.27.174:5000/teamx-kafka-base:latest
#         ports:
#         - containerPort: 9092
#           name: kafka-port
#         env:
#         - name: KAFKA_BIN_FILE
#           value: /kafka_/bin/kafka-server-start.sh
#         - name: KAFKA_PROPS_FILE
#           value: /kafka_/config/server.properties
#         - name: KAFKA_API_VERSIONS_BIN_FILE
#           value: /kafka_/bin/kafka-broker-api-versions.sh
#         # - name: ADVERTISED_IP
#         #   value: 127.0.0.1
#         # - name: ZOOKEEPER_IP
#         #   value: 10.244.1.3
#         - name: BROKER_ID
#           value: '0'
#         command:
#         - $(KAFKA_BIN_FILE)
#         - $(KAFKA_PROPS_FILE)
#         - --override
#         - listeners=PLAINTEXT://:9092
#         - --override
#         - advertised.listeners=PLAINTEXT://$(KUBERNETES_SERVICE_HOST):9092
#         #- advertised.listeners=PLAINTEXT://$(ADVERTISED_IP):9092
#         - --override
#         - listener.security.protocol.map=PLAINTEXT
#         - --override
#         - listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
#         - --override
#         - zookeeper.connect=$(TEAMX_ZOOKEEPER_SERVICE_HOST):$(TEAMX_ZOOKEEPER_SERVICE_PORT)
#         #- zookeeper.connect=$(ZOOKEEPER_IP):2181
#         - --override
#         - broker.id=$(BROKER_ID)
# #       volumeMounts:
# #       - mountPath: '/' #/kafka_/var/lib/kafka/data/ #/data/kafkainternal #/usr/share/kafka/internal
# #         name: kafkainternal
# # volumeClaimTemplates:
# # - metadata:
# #     name: kafkainternal
# #   spec:
# #     accessModes: [ "ReadWriteOnce" ]
# #     #storageClassName: fast
# #     resources:
# #       requests:
# #         storage: 1Mi
# #         #1Gi
